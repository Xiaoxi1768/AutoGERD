{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8615fd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import logging\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import argparse\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# import resnet_test\n",
    "\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "# import ResNet50\n",
    "# import DistributedResnet50.image_classification.resnet as nvmodels\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98470684",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO,\n",
    "                    filename='ResNet50_last_info.log',\n",
    "                    filemode='a',\n",
    "                    format='%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s')\n",
    "\n",
    "    \n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        # 定义第一个全连接层，将输入通道数压缩为 in_channels // reduction\n",
    "        self.fc1 = nn.Linear(in_channels, in_channels // reduction)\n",
    "        # 定义第二个全连接层，将通道数恢复为原始输入通道数\n",
    "        self.fc2 = nn.Linear(in_channels // reduction, in_channels)\n",
    "        # 定义Sigmoid激活函数，用于生成注意力权重\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 获取输入张量的 batch_size 和 channels\n",
    "        batch_size, channels, _, _ = x.size()\n",
    "        # 对输入张量的空间维度（高度和宽度）进行全局平均池化\n",
    "        squeeze = torch.mean(x, dim=(2, 3))\n",
    "        # 通过第一个全连接层进行通道压缩\n",
    "        squeeze = self.fc1(squeeze)\n",
    "        # 通过ReLU激活函数和第二个全连接层进行通道扩展\n",
    "        squeeze = self.fc2(F.relu(squeeze))\n",
    "        # 使用Sigmoid生成注意力权重，并调整形状以匹配输入张量的维度\n",
    "        attention = self.sigmoid(squeeze).view(batch_size, channels, 1, 1)\n",
    "        # 将注意力权重应用到输入张量上，进行通道加权\n",
    "        return x * attention\n",
    "\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super(CBAM, self).__init__()\n",
    "        # 通道注意力模块（SEBlock），用于学习通道间的注意力权重\n",
    "        self.channel_attention = SEBlock(in_channels, reduction)\n",
    "        # 空间注意力模块，使用1x1卷积核学习空间注意力权重\n",
    "        self.spatial_attention = nn.Conv2d(2, 1, kernel_size=7, padding=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 应用通道注意力模块，对输入特征进行通道加权\n",
    "        x = self.channel_attention(x)\n",
    "        # 计算输入特征在通道维度上的平均值\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        # 计算输入特征在通道维度上的最大值\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        # 将平均值和最大值拼接在一起\n",
    "        spatial_out = torch.cat([avg_out, max_out], dim=1)\n",
    "        # 通过空间注意力模块学习空间注意力权重\n",
    "        spatial_out = self.spatial_attention(spatial_out)\n",
    "        # 使用Sigmoid激活函数生成空间注意力权重\n",
    "        spatial_attention = torch.sigmoid(spatial_out)\n",
    "        # 将空间注意力权重应用到输入特征上，进行空间加权\n",
    "        return x * spatial_attention\n",
    "\n",
    "\n",
    "class DualAttentionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super(DualAttentionBlock, self).__init__()\n",
    "        # 通道注意力模块（SEBlock），用于学习通道间的注意力权重\n",
    "        self.channel_attention = SEBlock(in_channels, reduction)\n",
    "        # 空间注意力模块（CBAM），用于学习空间上的注意力权重\n",
    "        self.spatial_attention = CBAM(in_channels, reduction)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 应用通道注意力模块，对输入特征进行通道加权\n",
    "        x = self.channel_attention(x)\n",
    "        # 应用空间注意力模块，对输入特征进行空间加权\n",
    "        x = self.spatial_attention(x)\n",
    "        return x\n",
    "\n",
    "class AttentionModule(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(AttentionModule, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels // 16, kernel_size=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(in_channels // 16, in_channels, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention = self.conv1(x)\n",
    "        attention = self.relu(attention)\n",
    "        attention = self.conv2(attention)\n",
    "        attention = self.sigmoid(attention)\n",
    "        return x * attention\n",
    "\n",
    "\n",
    "\n",
    "class Model2_3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model2_3, self).__init__()\n",
    "        # 减少通道数\n",
    "        self.conv1 = nn.Conv2d(148, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        # 增加空间维度\n",
    "        self.deconv1 = nn.ConvTranspose2d(16, 8, kernel_size=4, stride=2, padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(8, 4, kernel_size=4, stride=2, padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(4, 3, kernel_size=4, stride=2, padding=1)\n",
    "        \n",
    "        # 最终调整到目标尺寸\n",
    "        self.final_conv = nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1)\n",
    "        self.upsample = nn.Upsample(size=(224, 224), mode='bilinear', align_corners=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 减少通道数\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.bn1(x)\n",
    "        # 增加空间维度\n",
    "        x = F.relu(self.deconv1(x))\n",
    "        x = F.relu(self.deconv2(x))\n",
    "        x = F.relu(self.deconv3(x))\n",
    "        \n",
    "        # 最终调整到目标尺寸\n",
    "        x = self.final_conv(x)\n",
    "        x = self.upsample(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class ResNetWithAttention(nn.Module):\n",
    "    def __init__(self, attention_cls, pretrained=True):\n",
    "        super(ResNetWithAttention, self).__init__()\n",
    "\n",
    "        self.deconv1 = nn.ConvTranspose2d(148, 128, kernel_size=4, stride=2, padding=1)  # 32x32 -> 64x64\n",
    "        self.deconv2 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)   # 64x64 -> 128x128\n",
    "        self.deconv3 = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1)    # 128x128 -> 256x256\n",
    "        \n",
    "        # 减少通道数\n",
    "        self.conv1 = nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(8, 3, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # 最终调整到目标尺寸\n",
    "        self.upsample = nn.Upsample(size=(224, 224), mode='bilinear', align_corners=False)\n",
    "        self.conv4 = nn.Conv2d(6, 3, kernel_size=3, stride=1, padding=1)\n",
    "        # 使用预训练的 ResNet50\n",
    "        self.base_model = models.resnet50(pretrained=pretrained)\n",
    "\n",
    "        # 创建注意力模块\n",
    "        # self.attention_layer1 = attention_cls(64)  # 第一层卷积后\n",
    "        self.attention_layer2 = attention_cls(2048)  # 最后一层卷积后\n",
    "\n",
    "    def forward(self, x,img):\n",
    "        # ResNet50的前向传播过程\n",
    "        a = []\n",
    "        a.append(x)\n",
    "        x = F.relu(self.deconv1(x))  # [148, 32, 32] -> [128, 64, 64]\n",
    "        # plt.imsave('../output/temp_data/128_64_64.png',temp)\n",
    "        x = F.relu(self.deconv2(x))  # [128, 64, 64] -> [64, 128, 128]\n",
    "        x = F.relu(self.deconv3(x))  # [64, 128, 128] -> [32, 256, 256]\n",
    "        a.append(x)\n",
    "        # 减少通道数\n",
    "        x = F.relu(self.conv1(x))  # [32, 256, 256] -> [16, 256, 256]\n",
    "        x = F.relu(self.conv2(x))  # [16, 256, 256] -> [8, 256, 256]\n",
    "        x = self.conv3(x)          # [8, 256, 256] -> [4, 256, 256]\n",
    "        a.append(x)\n",
    "        # 最终调整到目标尺寸\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat((x,img),dim=1)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.base_model.conv1(x)  # 初始卷积层\n",
    "        x = self.base_model.bn1(x)  # 批归一化\n",
    "        x = self.base_model.relu(x)  # 激活函数\n",
    "        a.append(x)\n",
    "        \n",
    "\n",
    "        # 最大池化层\n",
    "        x = self.base_model.maxpool(x)\n",
    "        # ResNet的残差层\n",
    "        x = self.base_model.layer1(x)\n",
    "        x = self.base_model.layer2(x)\n",
    "        x = self.base_model.layer3(x)\n",
    "        x = self.base_model.layer4(x)\n",
    "        \n",
    "        # 第二个注意力模块：最后一层卷积后\n",
    "        x = self.attention_layer2(x)\n",
    "        \n",
    "        # 平均池化\n",
    "        x = self.base_model.avgpool(x)\n",
    "        \n",
    "        # 展平并通过全连接层\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.base_model.fc(x)\n",
    "        a.append(x)\n",
    "        return x,a\n",
    "\n",
    "\n",
    "\n",
    "# 数据读取\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize([224,224]),    # 将图片短边缩放至224，长宽比保持不变：\n",
    "    transforms.RandomHorizontalFlip(),   #将图片随机翻转\n",
    "    transforms.ToTensor()          #把图片进行归一化，并把数据转换成Tensor类型\n",
    "])\n",
    "\n",
    "corr = pd.read_csv('./corr.csv',header=0,index_col=0).values\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, img_path, transform=transforms):\n",
    "        super(MyDataset, self).__init__()\n",
    "\n",
    "        \n",
    "        self.img = img_path.loc[:,'path'].values.tolist()\n",
    "        self.label = img_path.loc[:,'label'].values.tolist()\n",
    "        self.date = img_path.drop(columns=['path','label']).values.tolist()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img = self.img[item]\n",
    "        label = self.label[item]\n",
    "        data = self.date[item]\n",
    "        xl = data*corr*data\n",
    "        # logging.info(\"path:\"+img)\n",
    "        # xl = torch.from_numpy(np.pad(xl,32*3,'constant'))\n",
    "        xl = torch.from_numpy(xl).float()\n",
    "        xl = xl.reshape(1, 32,32)\n",
    "        img = Image.open(img).convert('RGB')\n",
    "\n",
    "        # 此时img是PIL.Image类型   label是str类型\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        for i in range(0,7):\n",
    "            for j in range(0,7):\n",
    "                xl = torch.cat((xl,img[:,i*32:(i+1)*32,j*32:(j+1)*32]), dim=0)\n",
    "        label = np.array(label).astype(np.int64)\n",
    "        label = torch.from_numpy(label)\n",
    "        # img = torch.cat((img, xl), dim=0)\n",
    "        xl.reshape(1,148,32,32)\n",
    "        # logging.info(\"size:\"+str(xl.size()))\n",
    "\n",
    "        return xl, img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6404ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('../output/temp_data/train.csv',header=0,index_col=0)\n",
    "image_paths = x.iloc[0:2,:]\n",
    "train_image_paths = image_paths\n",
    "train_image_paths.reset_index(drop=True,inplace=True)\n",
    "train_dataset = MyDataset(train_image_paths)\n",
    "valid_dataset = MyDataset(train_image_paths)\n",
    "# train_data_loader = DataLoader(dataset=train_dataset, batch_size=4, shuffle=True, num_workers=8, pin_memory=True, drop_last=True)\n",
    "valid_data_loader = DataLoader(dataset=valid_dataset, batch_size=1, shuffle=True,num_workers=8, pin_memory=True, drop_last=True)\n",
    "train_data_loader = DataLoader(dataset=train_dataset, batch_size=1, shuffle=True, num_workers=8, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "154ec4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, criterion, optimizer, num_epochs, device, num_print, lr_scheduler=None, test_iter=None):\n",
    "    net.train()\n",
    "    record_train = list()\n",
    "    record_test = list()\n",
    "    #oyz\n",
    "    train_AUC = list()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"========== epoch: [{}/{}] ==========\".format(epoch + 1, num_epochs))\n",
    "        total, correct, train_loss = 0, 0, 0\n",
    "        start = time.time()\n",
    "        #oyz\n",
    "        pred_label = list()\n",
    "        true_label = list()\n",
    "\n",
    "        for i, (X,img, y) in enumerate(train_iter):\n",
    "            # print(X.size())\n",
    "            X, y ,img= X.to(device), y.to(device), img.to(device)\n",
    "            output,a = net(X,img)\n",
    "            loss = criterion(output, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            #     scaled_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            total += y.size(0)\n",
    "            correct += (output.argmax(dim=1) == y).sum().item()\n",
    "            # train_acc = 100.0 * correct / total\n",
    "            train_acc = 0\n",
    "\n",
    "            if (i + 1) % num_print == 0:\n",
    "                print(\"step: [{}/{}], train_loss: {:.3f} | train_acc: {:6.3f}% | lr: {:.6f}\" \\\n",
    "                    .format(i + 1, len(train_iter), \n",
    "                            train_loss, \n",
    "                            train_acc, get_cur_lr(optimizer)))\n",
    "        #     #oyz\n",
    "        #     pred_label+=list(output.argmax(dim=1).cpu().numpy())\n",
    "        #     true_label+=list(y.cpu().numpy())\n",
    "        # epoch_auc = roc_auc_score(true_label,pred_label)\n",
    "        # train_AUC.append(epoch_auc*100)\n",
    "\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        print(\"--- cost time: {:.4f}s ---\".format(time.time() - start))\n",
    "\n",
    "        if test_iter is not None:\n",
    "            record_test.append(test(net, test_iter, criterion, device))\n",
    "        # record_train.append(train_acc)\n",
    "\n",
    "    return record_train, record_test,a\n",
    "\n",
    "def test(net, test_iter, criterion, device):\n",
    "    total, correct = 0, 0\n",
    "    net.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(\"*************** test ***************\")\n",
    "        for X,img, y in test_iter:\n",
    "            X, y ,img= X.to(device), y.to(device),img.to(device)\n",
    "            output,a = net(X,img)\n",
    "            loss = criterion(output, y)\n",
    "\n",
    "            total += y.size(0)\n",
    "            correct += (output.argmax(dim=1) == y).sum().item()\n",
    "\n",
    "    # test_acc = 100.0 * correct / total\n",
    "    test_acc = 0\n",
    "\n",
    "    # print(\"test_loss: {:.3f} | test_acc: {:6.3f}%\"\\\n",
    "    #     .format(loss.item(), test_acc))\n",
    "    # print(\"************************************\\n\")\n",
    "    net.train()\n",
    "\n",
    "    return test_acc,a,X,img\n",
    "\n",
    "def get_cur_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27ec031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import cv2\n",
    "from sklearn.decomposition import PCA  # 用于PCA可视化\n",
    "\n",
    "def tensor_to_image(tensor, method='pca_visualization', normalize=True):\n",
    "    \"\"\"\n",
    "    将三维张量[C, H, W]转换为图像\n",
    "    \n",
    "    参数:\n",
    "    tensor: 输入张量，形状为[C, H, W]（如[148, 32, 32]）\n",
    "    method: 转换方法，可选：\n",
    "            - 'channel_average': 通道平均（灰度图）\n",
    "            - 'channel_max': 通道最大值（灰度图）\n",
    "            - 'channel_selection': 选择方差最大的通道（灰度图）\n",
    "            - 'grid': 网格排列显示所有通道（灰度图）\n",
    "            - 'pca_visualization': PCA降维为RGB图像\n",
    "    normalize: 是否归一化到[0, 1]范围\n",
    "    \n",
    "    返回:\n",
    "    image: 转换后的图像数组\n",
    "    \"\"\"\n",
    "    # 确保输入为numpy数组\n",
    "    if isinstance(tensor, torch.Tensor):\n",
    "        tensor = tensor.cpu().numpy()\n",
    "    \n",
    "    # 维度校验\n",
    "    if tensor.ndim != 3:\n",
    "        raise ValueError(f\"输入应为3维张量，当前维度: {tensor.ndim}\")\n",
    "    C, H, W = tensor.shape\n",
    "    \n",
    "    # 核心转换逻辑\n",
    "    if method == 'channel_average':\n",
    "        image = np.mean(tensor, axis=0)  # 沿通道维度求平均\n",
    "    \n",
    "    elif method == 'channel_max':\n",
    "        image = np.max(tensor, axis=0)  # 取通道最大值\n",
    "    \n",
    "    elif method == 'channel_selection':\n",
    "        # 计算各通道方差，选择信息量最大的通道\n",
    "        channel_var = np.var(tensor, axis=(1, 2))\n",
    "        best_channel = np.argmax(channel_var)\n",
    "        image = tensor[best_channel]\n",
    "    \n",
    "    elif method == 'grid':\n",
    "        # 网格排列所有通道（适用于C较小的情况，148通道会生成12×13网格）\n",
    "        grid_h = int(np.ceil(np.sqrt(C)))\n",
    "        grid_w = int(np.ceil(C / grid_h))\n",
    "        canvas = np.zeros((grid_h * H, grid_w * W))\n",
    "        for i in range(C):\n",
    "            row, col = i // grid_w, i % grid_w\n",
    "            canvas[row*H:(row+1)*H, col*W:(col+1)*W] = tensor[i]\n",
    "        image = canvas\n",
    "    \n",
    "    elif method == 'pca_visualization':\n",
    "        try:\n",
    "            # PCA降维到3通道（RGB）\n",
    "            flat_features = tensor.reshape(C, -1).T  # [H*W, C]\n",
    "            if flat_features.shape[0] < 3:\n",
    "                raise ValueError(f\"样本数不足(需要≥3，当前{flat_features.shape[0]})\")\n",
    "            pca = PCA(n_components=3)\n",
    "            pca_features = pca.fit_transform(flat_features)\n",
    "            image = pca_features.reshape(H, W, 3)\n",
    "            # 归一化到[0, 1]\n",
    "            image = (image - image.min()) / (image.max() - image.min() + 1e-8)\n",
    "            return image\n",
    "        except ImportError:\n",
    "            print(\"警告：缺少scikit-learn，将使用通道平均替代\")\n",
    "            method = 'channel_average'\n",
    "            return tensor_to_image(tensor, method, normalize)\n",
    "        except Exception as e:\n",
    "            print(f\"PCA错误: {e}，将使用通道平均替代\")\n",
    "            method = 'channel_average'\n",
    "            return tensor_to_image(tensor, method, normalize)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"不支持的方法: {method}，可选：channel_average/channel_max/channel_selection/grid/pca_visualization\")\n",
    "    \n",
    "    # 归一化处理（仅针对灰度图方法）\n",
    "    if normalize:\n",
    "        if np.allclose(image, image[0, 0]):  # 处理常数张量\n",
    "            image = np.ones_like(image) * 0.5\n",
    "        else:\n",
    "            image = (image - image.min()) / (image.max() - image.min() + 1e-8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def visualize_tensor(tensor, method='pca_visualization', save_path=None, dpi=300):\n",
    "    \"\"\"可视化张量并保存图像\"\"\"\n",
    "    image = tensor_to_image(tensor, method)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8), dpi=dpi)\n",
    "    if method == 'pca_visualization':\n",
    "        plt.imshow(image)  # RGB图像\n",
    "    else:\n",
    "        plt.imshow(image, cmap='viridis')  # 灰度图，使用viridis色彩映射增强对比度\n",
    "    \n",
    "    plt.title(f'张量可视化 (方法: {method})', fontsize=14)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=dpi)\n",
    "        print(f\"图像已保存至: {save_path}\")\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dc4e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** test ***************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_649480/2393065185.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net = torch.load('./ResNet50_last.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 112, 112])\n",
      "原始图像最大值: 255.0\n",
      "原始图像最小值: 0.0\n",
      "[[7.7054840e-01 4.1642517e+01 0.0000000e+00 ... 2.8767084e-09\n",
      "  5.1425386e-10 1.7114751e-09]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 1.7048310e-10\n",
      "  1.7279334e-10 6.8290545e-10]\n",
      " [0.0000000e+00 1.5988974e+02 3.2151188e+01 ... 5.9908776e-09\n",
      "  0.0000000e+00 1.7221599e-09]\n",
      " ...\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 5.3299049e-10]\n",
      " [0.0000000e+00 5.8142786e+00 7.1580315e-01 ... 1.7053381e-08\n",
      "  0.0000000e+00 2.3635864e-09]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 2.0035904e-09\n",
      "  0.0000000e+00 1.3283100e-09]]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 1\n",
    "# '''\n",
    "# 训练到50轮已经收敛\n",
    "# '''\n",
    "# NUM_EPOCHS = 50\n",
    "# NUM_EPOCHS = 2\n",
    "NUM_CLASSES = 8\n",
    "LEARNING_RATE = 0.02\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 0.0005\n",
    "NUM_PRINT = 100\n",
    "def main():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    \n",
    "    # net = resnet_test.resnet50()\n",
    "    # net = models.resnet50(pretrained=True)\n",
    "    # model23 = Model2_3()\n",
    "    # attention_cls = DualAttentionBlock  # 可以替换为其他类型的注意力模块\n",
    "    # net = ResNetWithAttention(attention_cls)\n",
    "    # net = net.to(device)\n",
    "    net = torch.load('./ResNet50_last.pth')\n",
    "    net = net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.SGD(\n",
    "        net.parameters(),\n",
    "        lr=LEARNING_RATE,\n",
    "        momentum=MOMENTUM,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        nesterov=True\n",
    "    )\n",
    "\n",
    "    # net, optimizer = amp.initialize(net, optimizer, opt_level='O2')\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "    # record_train, record_test,a = train(net, train_data_loader, criterion, optimizer, NUM_EPOCHS, device, NUM_PRINT, lr_scheduler, valid_data_loader)\n",
    "    acc,b,X,img = test(net,valid_data_loader, criterion, device)\n",
    "    print(b[3].shape)\n",
    "    # print(img)\n",
    "    b = b[1].detach().cpu().numpy()\n",
    "    temp = b[0]\n",
    "    # print(f\"原始图像最大值: {np.max(b)}\")\n",
    "    # print(f\"原始图像最小值: {np.min(b)}\")\n",
    "    # image = np.sum(temp,axis=0)\n",
    "    image = temp[0]\n",
    "    image = (image - image.min()) / (image.max()-image.min())*255\n",
    "    # image = image.astype(np.uint8)\n",
    "    print(f\"原始图像最大值: {np.max(image)}\")\n",
    "    print(f\"原始图像最小值: {np.min(image)}\")\n",
    "    plt.imsave('../output/temp_data/4_256_256.png',image)\n",
    "    # methods = ['channel_average', 'channel_max', 'channel_selection', 'grid', 'pca_visualization']\n",
    "    # for method in methods:\n",
    "    #     visualize_tensor(temp[0], method=method, save_path=f'../output/temp_data/{method}.png')\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8825a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e35835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AICore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
